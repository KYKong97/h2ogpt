{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspaces/h2ogpt\")\n",
    "sys.path.append(\"/workspaces/h2ogpt/src\")\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import types\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from src.gpt_langchain import prep_langchain,get_existing_db\n",
    "from src.utils_langchain import _chunk_sources\n",
    "from src.gpt4all_llm import H2OLlamaCpp\n",
    "from src.utils import FakeTokenizer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from src.prompter import Prompter\n",
    "from src.gpt_langchain import get_template, get_docs_with_score, select_docs_with_score, split_merge_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(docs1):\n",
    "    if not isinstance(docs1, (list, tuple, types.GeneratorType)):\n",
    "        docs1 = [docs1]\n",
    "    for doci, doc in enumerate(docs1):\n",
    "        docs1[doci].page_content = '\\n'.join([x.strip() for x in doc.page_content.split(\"\\n\") if x.strip()])\n",
    "    return docs1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "pdf_doc = PyPDFLoader(\"../Adjuster Report.PDF\").load()\n",
    "docs = [x for x in pdf_doc if x.page_content]\n",
    "docs = clean_doc(docs)\n",
    "docs = _chunk_sources(docs,db_type='faiss')\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "hf_embedding_model.client.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, hf_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to listen to n_gpus: No module named 'llama_cpp_cuda'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from ../llamacpp_path/llama-2-7b-chat.Q6_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 5.15 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  5272.34 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     0.20 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     2.61 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n"
     ]
    }
   ],
   "source": [
    "prompt_type = 'llama2'\n",
    "prompt_dict=''\n",
    "system_prompt = 'Give me a summary that is well-structured yet consice.'\n",
    "prompter = Prompter(prompt_type, prompt_dict, debug=False, stream_output=False,\n",
    "                            system_prompt=system_prompt)\n",
    "\n",
    "model = H2OLlamaCpp(\n",
    "    model_path='../llamacpp_path/llama-2-7b-chat.Q6_K.gguf',\n",
    "    n_ctx=2048,\n",
    "    temperature=0.1,\n",
    "    top_p=0.7,\n",
    "    prompter=prompter\n",
    "\n",
    ")\n",
    "\n",
    "inner_tokenizer = FakeTokenizer(tokenizer=model.client, is_llama_cpp=True, model_max_length=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Where is the location of accident?'\n",
    "iinput = ''\n",
    "pre_prompt_query = 'Pay attention and remember the information below, which will help to answer the question or imperative after the context ends.'\n",
    "prompt_query = 'According to only the information in the document sources provided within the context above, write an insightful and well-structured response to: '\n",
    "pre_prompt_summary = 'In order to write a concise single-paragraph or bulleted list summary, pay attention to the following text.'\n",
    "prompt_summary = 'Using only the information in the document sources above, write a condensed and concise summary of key results (preferably as bullet points).'\n",
    "langchain_action = 'Extract'\n",
    "query_action = False\n",
    "summarize_action = True\n",
    "auto_reduce_chunks = False\n",
    "add_search_to_context = False\n",
    "system_prompt = 'Give a summary that is well-structured yet concise.'\n",
    "doc_json_mode = False\n",
    "\n",
    "template, template_if_no_docs, auto_reduce_chunks, query = \\\n",
    "        get_template(query, iinput,\n",
    "                     pre_prompt_query, prompt_query,\n",
    "                     pre_prompt_summary, prompt_summary,\n",
    "                     langchain_action,\n",
    "                     query_action,\n",
    "                     summarize_action,\n",
    "                     True,  # just to overestimate prompting\n",
    "                     auto_reduce_chunks,\n",
    "                     add_search_to_context,\n",
    "                     system_prompt,\n",
    "                     doc_json_mode,\n",
    "                     prompter=prompter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = query\n",
    "k_db = 10\n",
    "filter_kwargs = {}\n",
    "filter_kwargs_backup = {}\n",
    "db_type = 'faiss'\n",
    "text_context_list = []\n",
    "chunk_id_filter = None\n",
    "where_document_dict = {}\n",
    "verbose = False\n",
    "top_k_docs = 10\n",
    "one_doc_size = None\n",
    "tokenizer = inner_tokenizer\n",
    "max_input_tokens = 3840\n",
    "docs_token_handling = 'split_or_merge'\n",
    "docs_joiner = '\\n\\n'\n",
    "\n",
    "docs_with_score = get_docs_with_score(query_embedding, k_db,\n",
    "                                                  filter_kwargs,\n",
    "                                                  filter_kwargs_backup,\n",
    "                                                  db, db_type,\n",
    "                                                  text_context_list=text_context_list,\n",
    "                                                  chunk_id_filter=chunk_id_filter,\n",
    "                                                  where_document_dict=where_document_dict,\n",
    "                                                  verbose=verbose)\n",
    "\n",
    "docs_with_score = select_docs_with_score(docs_with_score, top_k_docs, one_doc_size)\n",
    "\n",
    "docs_with_score, max_doc_tokens = split_merge_docs(docs_with_score,\n",
    "                                                           tokenizer,\n",
    "                                                           max_input_tokens=max_input_tokens,\n",
    "                                                           docs_token_handling=docs_token_handling,\n",
    "                                                           joiner=docs_joiner,\n",
    "                                                           verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update template in case situation changed or did get docs\n",
    "    # then no new documents from database or not used, redo template\n",
    "    # got template earlier as estimate of template token size, here is final used version'\n",
    "\n",
    "iinput = ''\n",
    "pre_prompt_query = 'Pay attention and remember the information below, which will help to answer the question or imperative after the context ends.'\n",
    "prompt_query = 'According to only the information in the document sources provided within the context above, write an insightful and well-structured response to: '\n",
    "pre_prompt_summary = 'In order to write a concise single-paragraph or bulleted list summary, pay attention to the following text.'\n",
    "prompt_summary = 'Using only the information in the document sources above, write a condensed and concise summary of key results (preferably as bullet points).'\n",
    "got_any_docs = True\n",
    "\n",
    "template, template_if_no_docs, auto_reduce_chunks, query = \\\n",
    "    get_template(query, iinput,\n",
    "                    pre_prompt_query, prompt_query,\n",
    "                    pre_prompt_summary, prompt_summary,\n",
    "                    langchain_action,\n",
    "                    query_action,\n",
    "                    summarize_action,\n",
    "                    got_any_docs,\n",
    "                    auto_reduce_chunks,\n",
    "                    add_search_to_context,\n",
    "                    system_prompt,\n",
    "                    doc_json_mode,\n",
    "                    prompter=prompter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='5\\nLOCATION OF ACCIDENT\\nLocation  : At KM 24 Jalan Bahau – Kemayan, 72120 Jempol,\\nNegeri Sembilan.\\nType of Carriageway   : Double carriageway of bitumen surface .\\nTraffic Flow    : Two direction s.\\nOne lane, in the direction Jerantut.\\nOne lane, in the direction to  Serting .\\nCentre Demarcation   :         Double continuous white lines, separating opposing flow of\\ntraffic.\\nWidth of Lanes   : About 3m each .\\nRoad Signs    : Destinations/Directions.\\nVisibility    : Good.\\nLighting    : Streetlights .\\n\\n7\\nPhoto of scene of accident, facing  Jerantut .\\nCustodian ’s direction from  his residen ce at No. 13, Lorong 1, Jalan TM 3A, Taman\\nTanjung Minyak, 75250 Melaka to Taman Damak Utama, 27030 Damak,\\nJerantut, Pahang.\\nPhoto of scene of accident , facing  from Serting .\\nThird Party Driver ’s direction from  his residence at No. 253 Blok 11, Felda Lui Timur ,\\n72120 Bandar Seri Jempol, Negeri Sembilan  heading to grocery store  at Serting.\\n\\nRoad Condition at time of  : Good and well maintained.\\nAccident\\nWeather at time of accident  :          Fine.\\nTraffic volume at time of       :          Mild.\\naccident\\nCustodian ’s direction   : In the direction  to Taman Damak Utama, 27030 Damak,\\nJerantut, Pahang.\\nRight side of road\\nis flanked by    : Rubber Plantation .\\nLeft side of road\\nis flanked by                       :         Oil Palm Plantation .\\nPhotos and Sketch Plan of Location of Accident\\nKEYS:\\nCovered  Vehicle\\nThird Party Motorc ar\\n\\nDue to the collision , his motorcar  moves  forward  to the right side, before coming to a halt\\ncomplete stopped.\\nOn impact, he and his family members sustained injuries and his motorcar  was damaged on the\\nfront section.\\nPasse r-by contacted 999 and a few minutes later, an ambulance arrived and conveyed all of them\\nto Jempol Hospital, Jalan Bahagia, Bandar Seri Jempol, 72120 Bandar Seri Jempol, Negeri\\nSembilan, for medical treatment.\\n\\n34\\nDAMAGE SUSTAINED BY THE ACCIDENT VEHICLES\\nCovered Vehicle\\nThe Custodian  advised that the Covered  Vehicle was damaged on the front right section.\\nItem  Nature of Damage\\nFront Bumper\\nBonnet\\nHeadlamp  (RH & LH)\\nFront Mudg uard (RH & LH)\\nAir Conditioner tank\\nWater Tank\\nFront Door (RH & LH)\\nLog arm\\nAirbag  (RH & LH)\\n:\\n:\\n:\\n:\\n:\\n:\\n:\\n:\\n: Kink. Folded.\\nKink. Folded.\\nBroken.\\nKink. Folded.\\nBroken.\\nBroken.\\nDented .\\nBent.\\nDeployed.\\nPoint of Impact  : Front section.\\nName of workshop /cost of\\nrepairs\\n\\nAfter the collision , the Covered Vehicle was spu n at the point of collision, facing Serting .\\nAs for the  Third Party motorcar was move  forward to the right side, before coming to a halt\\ncomplete stopped, facing  Serting.\\nOn impact, the Custodian and his wife/Participant sustained injuries  and the Covered\\nVehicle was damaged on the front section.\\nHe noticed the Third Party Driver , who was accompanied by his wife, Madam Zainorani Binti\\n\\n6\\nSketch Plan of Scene of Accident , as confirmed by the Third Party Driver\\n(Not to scale).\\nKM 24 Jalan\\nBahau - Kemayan  To\\nJerantut\\nTo\\nSerting  Oil Palm\\nPlantation  Rubber\\nPlantation\\n\\nWeather was fine and it was bright. Traffic was m ild.  Visibility was good.  Road well maintained.\\nHe was driving along Jalan Bahau – Kemayan, 72120 Jempol, Negeri Sembilan.\\nHe was accompanied by the Participant, Puan Rafidah Binti Ahmad , who sat as front seat\\npassenger .\\nTravelling speed was about 70 km/h to 80 km/h.\\nAt KM 24  of the stretch street , suddenly he lost control of the Covered Vehicle.\\nThe Covered Vehicle then skidded to the left road shoulder .\\n\\n30\\nTHIRD PARTY PASSENGER  (Third Party Driver’s 2nd son)\\nName\\n: Muhammad Hudzayr Bin Mohamad Sani\\nNRIC No.\\n: 100309 -05-0603\\nAge\\n: 12 years old\\nMarital status as the time of\\naccident  : Single\\nCurrent Address\\n: No. 253 , Blok 11, Felda Lui Timur, 72120 Bandar Seri\\nJempol, Negeri Sembilan.\\nEmployment\\nOccupation/employer at time\\n: Standard 6 Student at Sekolah Kebangsaan  Felda Lui\\nTimur , No. 10, Kampung Lui Timur (Felda), 72120, Negeri\\nSembilan .\\nIncome at time of accident\\n\\nyears old), who sat as rear passengers.\\nTravelling speed was about 80 km/h to 90 km/h.\\nAt KM 24 on the stretch of  Jalan Bahau – Kemayan , he noticed that the Covered Vehicle arrived\\nfrom the oncoming/opposite direction had lost control of the Covered Vehicle.\\nThe Covered Vehicle then veered forward to the right, cut across the double continuous white\\nlines, encroached into his path of travel and collided head -on against with his motorcar.', metadata={'source': '../Adjuster Report.PDF', 'page': 4, 'chunk_id': 7, 'orig_index': 0}),\n",
       "  0.7538886)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a prompt template with input variables\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Format the prompt template with a value for the input variable\n",
    "prompt = prompt_template.format(text=docs_with_score[0][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1603.19 ms\n",
      "llama_print_timings:      sample time =      44.00 ms /   256 runs   (    0.17 ms per token,  5818.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  292141.93 ms /  1604 tokens (  182.13 ms per token,     5.49 tokens per second)\n",
      "llama_print_timings:        eval time =   64301.72 ms /   255 runs   (  252.16 ms per token,     3.97 tokens per second)\n",
      "llama_print_timings:       total time =  357672.55 ms /  1859 tokens\n"
     ]
    }
   ],
   "source": [
    "answer = model._call(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a condensed and concise summary of key results based on the provided document sources:\n",
      "• Location of accident: KM 24 Jalan Bahau – Kemayan, Negeri Sembilan.\n",
      "• Type of carriageway: Double carriageway of bitumen surface.\n",
      "• Traffic flow: Two directions, one lane in each direction.\n",
      "• Centre demarcation: Double continuous white lines separating opposing flow of traffic.\n",
      "• Width of lanes: About 3m each.\n",
      "• Road signs: Destinations/Directions.\n",
      "• Visibility: Good.\n",
      "• Lighting: Streetlights.\n",
      "• Weather: Fine.\n",
      "• Time of accident: Mild traffic volume.\n",
      "• Custodian's direction: In the direction of Taman Damak Utama, 27030 Damak, Jerantut, Pahang.\n",
      "• Third Party Driver's direction: From his residence at No. 253 Blok 11, Felda Lui Timur, 72120 Bandar Seri Jempol, Negeri Sembilan, heading to\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
